%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% LIVECOMS ARTICLE TEMPLATE FOR BEST PRACTICES GUIDE
%%% ADAPTED FROM ELIFE ARTICLE TEMPLATE (8/10/2017)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PREAMBLE
\documentclass[9pt,bestpractices,pubversion]{livecoms}
% Use the 'onehalfspacing' option for 1.5 line spacing
% Use the 'doublespacing' option for 2.0 line spacing
% Use the 'lineno' option for adding line numbers.
% The 'bestpractices' option for indicates that this is a best practices guide.
% Omit the bestpractices option to remove the marking as a LiveCoMS paper.
% Please note that these options may affect formatting.

\usepackage{lipsum} % Required to insert dummy text
\usepackage[version=4]{mhchem}
\usepackage{siunitx}
\usepackage{url}
\DeclareSIUnit\Molar{M}
\usepackage[italic]{mathastext}
\graphicspath{{figures/}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% IMPORTANT USER CONFIGURATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[most]{tcolorbox}
\usepackage{enumitem,amssymb}
\usepackage{textgreek}
\usepackage{changepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Added to allow customisation of table of contents
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tocloft}
\usepackage{xcolor}
\usepackage{todonotes}

% Define custom commands for colored TOC entries
\newcommand{\tocgreen}[1]{\textcolor{green}{#1}}
\newcommand{\tocorange}[1]{\textcolor{orange}{#1}}
\newcommand{\tocred}[1]{\textcolor{red}{#1}}

% Define custom commands for TOC entries with comments
\makeatletter
\newcommand{\tocsectioncomment}[1]{%
  \addtocontents{toc}{%
    {\leftskip \cftsecindent\relax
     \advance\leftskip \cftsecnumwidth\relax
     \rightskip \@tocrmarg\relax
     \textit{#1}\protect\par}}%
  \textit{#1}\par}

% Command for subsection comments in TOC
\newcommand{\tocsubsectioncomment}[1]{%
  \addtocontents{toc}{%
    {\leftskip \cftsubsecindent\relax
     \advance\leftskip \cftsubsecnumwidth\relax
     \rightskip \@tocrmarg\relax
     \textit{#1}\protect\par}}%
  \textit{#1}\par}

% Command for subsubsection comments in TOC
\newcommand{\tocsubsubsectioncomment}[1]{%
  \addtocontents{toc}{%
    {\leftskip \cftsubsecindent\relax
     \advance\leftskip \cftsubsubsecnumwidth\relax
     \rightskip \@tocrmarg\relax
     \textit{#1}\protect\par}}%
  \textit{#1}\par}

\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\versionnumber}{0.1} % you should update the minor version number in preprints and major version number of submissions.
\newcommand{\githubrepository}{\url{https://github.com/alchemistry/largescale-alchemy-best-practices}} %this should be the main github repository for this article
\newcommand{\expect}[1]{\left\langle{#1}\right\rangle}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE SETUP
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Best Practices for Multiple Alchemical Free Energy Calculations [Article v\versionnumber]}
\author[1*]{Antonia S. J. S. Mey}
\author[2]{Bryce K. Allen}
\author[3]{Hannah E. Bruce Macdonald}
\author[3*]{John D. Chodera}
\author[9]{Vytautas Gapsys}
\author[9]{David F. Hahn}
\author[1,10]{Maximilian Kuhn}
\author[1]{Julien Michel}
\author[4*]{David L. Mobley}
\author[5]{Levi N. Naden}
\author[6]{Samarjeet Prasad}
\author[11,12]{Benjamin Ries}
\author[2,7]{Andrea Rizzi}
\author[1]{Jenke Scheen}
\author[8*]{Michael R. Shirts}
\author[9]{Gary Tresadern}
\author[2]{Huafeng Xu}
%
\affil[1]{EaStCHEM School of Chemistry, David Brewster Road, Joseph Black Building, The King's Buildings, Edinburgh, EH9 3FJ, UK}
\affil[2]{Silicon Therapeutics, Boston, MA, USA}
\affil[3]{Computational and Systems Biology Program, Sloan Kettering Institute, Memorial Sloan Kettering Cancer Center, New York NY, USA}
\affil[4]{Departments of Pharmaceutical Sciences and Chemistry, University of California, Irvine, Irvine, USA}
\affil[5]{Molecular Sciences Software Institute, Blacksburg VA, USA}
\affil[6]{National Institutes of Health, Bethesda, MD, USA}
\affil[7]{Tri-Institutional Training Program in Computational Biology and Medicine, New York, NY, USA}
\affil[8]{University of Colorado Boulder, Boulder, CO, USA}
\affil[9]{Computational Chemistry, Janssen Research \& Development, Turnhoutseweg 30, Beerse B-2340, Belgium}
\affil[10]{Cresset, Cambridgeshire, UK}
\affil[11]{Boehringer Ingelheim Pharma GmbH \& Co KG, Medicinal Chemistry, Birkendorfer Str 65, 88397 Biberach an der Riss, Germany}
\affil[12]{Open Free Energy, Open Molecular Software Foundation, Davis, CA, 95616, United State}

%
\corr{antonia.mey@ed.ac.uk}{ASJSM}
\corr{john.chodera@choderalab.org}{JDC}
\corr{dmobley@mobleylab.org}{DLM}
\corr{michael.shirts@colorado.edu}{MRS}

\orcid{Antonia S. J. S. Mey}{0000-0001-7512-5252}
\orcid{Bryce Allen}{0000-0002-0804-8127}
\orcid{Hannah E. Bruce Macdonald}{0000-0002-5562-6866}
\orcid{John D. Chodera}{0000-0003-0542-119X}
\orcid{Maximilian Kuhn}{0000-0002-2811-3934}
\orcid{Julien Michel}{0000-0003-0360-1760}
\orcid{David L. Mobley}{0000-0002-1083-5533}
\orcid{Levi N. Naden}{0000-0002-3692-5027}
\orcid{Samarjeet Prasad}{0000-0001-8320-6482}
\orcid{Benjamin Ries}{0000-0002-0945-8304}
\orcid{Andrea Rizzi}{0000-0001-7693-2013}
\orcid{Jenke Scheen}{0000-0001-9781-0445}
\orcid{Michael R. Shirts}{0000-0003-3249-1097}
\orcid{Gary Tresadern}{0000-0002-4801-1644}
\orcid{Huafeng Xu}{0000-0001-5447-0452}
\orcid{David F. Hahn}{0000-0003-2830-6880}
\orcid{Vytautas Gapsys}{0000-0002-6761-7780}

\blurb{This LiveCoMS document is maintained online on GitHub at \githubrepository; to provide feedback, suggestions, or help improve it, please visit the GitHub repository and participate via the issue tracker.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PUBLICATION INFORMATION
%%% Fill out these parameters when available
%%% These are used when the "pubversion" option is invoked
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \pubDOI{10.33011/livecoms.2.1.18378}
% \pubvolume{2}
% \pubyear{2020}
% \articlenum{18378}
% \datereceived{5 August 2020}
% \dateaccepted{25 November 2020}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE START
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{frontmatter}
\maketitle
\todo[inline, color=green!20]{@Volunteer update initial contributor list to reflect sections copied from part 1.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Abstract
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}


\todo[inline, color=green!20]{
    
The original best practices guide will be split into two documents: the first will gives best practices for running a \emp{single} calculation (and give details on theory/ system-specific setup), while the second will give best practices for running \emp{multiple} calculations (with a focus on automation). The first will become version 2.0 of the current guide, while the second will be submitted as a new manuscript.

This document outlines the contents of the second document for multiple calculations. This will also have a focus on methods for automation.
}

\todo[inline, color=green!20]{@Volunteer Update abstract to highlight the split of the document and focus on multiple calculations.}

Alchemical free energy calculations are a useful tool for predicting free energy differences associated with the transfer of molecules from one environment to another.
The hallmark of these methods is the use of "bridging" potential energy functions representing \emph{alchemical} intermediate states that cannot exist as real chemical species. The data collected from these bridging alchemical thermodynamic states allows the efficient computation of transfer free energies (or differences in transfer free energies) with orders of magnitude less simulation time than simulating the transfer process directly. 
While these methods are highly flexible, care must be taken in avoiding common pitfalls to ensure that computed free energy differences can be robust and reproducible for the chosen force field, and that appropriate corrections are included to permit direct comparison with experimental data.

In this paper, we review current best practices for several popular application domains of alchemical free energy calculations performed with equilibrium simulations, in particular relative and absolute small molecule binding free energy calculations to biomolecular targets.

\end{abstract}
\end{frontmatter}

\newpage
% Add a comment to the top of the contents page
\addtocontents{toc}{\vskip2pt\noindent\textcolor{green}{\textbf{Green sections}: Minimal revisions required}\par\vskip2pt}
\addtocontents{toc}{\vskip2pt\noindent\textcolor{orange}{\textbf{Orange sections}: Substantial revisions required}\par\vskip2pt}
\addtocontents{toc}{\vskip2pt\noindent\textcolor{red}{\textbf{Red sections}: Needs written from scratch.}\par\vskip2pt}

\tableofcontents

\newpage

\section{\tocred{What are alchemical free energy methods?}}
\tocsectioncomment{@Volunteer to add section briefly summarising the same section in the first paper, directing readers to the first paper, and highlighting their use a high-throughput, multiple calculation setting.}
\label{sec:intro}

\section{\tocred{Prerequisites and Scope}}
\tocsectioncomment{@Volunteer to update clearly delineating the separation between the first (single calculation) and second (multiple caluclations) papers.}
\tocsectioncomment{@Volunteers to a) integrate the sections cut directly from v1 of the paper and b) consider adding further sections as required.}
\label{sec:pre}


\section{\tocorange{Is my problem suitable for an alchemical free energy calculations?}}
\tocsectioncomment{Content copied from "How should alchemical simulations be applied to drug discovery?" in the first paper. @Volunteer to better integrate this into the second paper.}
\label{sec:problem_suitable}

\subsection{Is the expected accuracy of the computation sufficient?}
\label{subsec:accuracy}
The requisite level of accuracy is another important consideration. If the
goal is to guide lead optimization when many compounds will be
synthesized, free energy calculations can be appealing even with
accuracies in the 1--2 kcal/mol range~\cite{mobley2012perspective}, but if the number of compounds to be synthesized is very small, this accuracy may not be enough to provide much value.

Here we provide a simple estimate of the value provided by alchemical
free energy calculations in lead optimization. Let $P(\Delta\Delta
G)$ be the probability distribution of the changes in the binding free
energies of a new set of molecules during one round of lead
optimization, and let $P(\Delta\Delta G^\dagger|\Delta\Delta G)$ be the
conditional probability of the binding free energy change computed by
the free energy calculations, $\Delta\Delta G^\dagger$, given the actual
change $\Delta\Delta G$. The latter conditional probability can be modeled
by a normal distribution
\begin{equation}
  P(\Delta\Delta G^\dagger|\Delta\Delta G) = \frac{1}{\sqrt{2\pi\sigma^2}}
  \exp\left(-\frac{(\Delta\Delta G^\dagger - \Delta\Delta G)^2}{2\sigma^2}\right),
  \label{eqn:free-energy-distribution}
\end{equation}
where $\sigma$ signifies the accuracy of free energy calculations.
Here we assume that there is no systematic bias in the free energy
calculations, i.e., on average, the free energy change computed by
free energy calculations agrees with the actual free energy change. Additional analysis of this type is presented in Brown et al.~\cite{brown2010free}

In lead optimization guided by free energy calculations, we will likely only
synthesize and experimentally test molecules that are predicted to
have favorable free energy changes. We are thus interested in how
often a molecule predicted to bind stronger actually turns out to
bind stronger. In other words, we are interested in the conditional
probability:
\begin{equation}
  P(\Delta\Delta G<0|\Delta\Delta G^\dagger<0).
  \label{eqn:true-positive}
\end{equation}

For illustrative purposes, consider a proposed set of new molecules, and assume that the changes proposed in these molecules yield a set of relative binding free energies that follow a normal
distribution. That is, assume that the standard deviation in the relative binding free energies for the changes represented is $RT\ln 5$
(corresponding to a 5-fold change in the binding affinities), and that
1 in 10 new molecules have increased binding affinity ($\Delta\Delta G
\leq 0$). Under such assumptions, the conditional probability in
Eq.~\ref{eqn:true-positive} can be easily computed. 

If the accuracy of a collection of free energy calculations is $\sigma = 1$ kcal/mol, $P(\Delta\Delta
G<0|\Delta\Delta G^\dagger<0) = 0.35$, which means that out of every
10 molecules selected for predicted favorable free energy change, on
average 3.5 molecules will have actual favorable free energy change.
In other words, selection by free energy calculations yields 3.5 times
more molecules of improved affinities than selection without free
energy calculations under these assumptions.
  
Available computational resources and timescales of motion also factor
into this initial analysis. An individual free energy calculation
involves simulations at many different intermediate states (perhaps
20-40 or more) and each of these must typically be long enough to
capture the relevant motions in the system. If such motions are
microsecond events or longer, the computational cost of running 20-40
microsecond or longer simulations for each of $N$ ligands will likely be
prohibitive for most users with today's hardware. On the other hand, if key motions are fast and minimal (as is often assumed in practice), much shorter simulations may be sufficient. 

\subsection{Can I afford the calculation?}
\label{subsec:affordability}
Furthermore, are available computational resources sufficient that throughput will be reasonable compared to needs of experimental collaborators working on
this system? How many ligands ($N$) can you afford to handle given
your computational resources? As cloud computing becomes more available, in-house GPU clusters may not be necessary if calculations are not run on a regular basis.
This analysis should be done up front as part of ``counting the cost''
of involvement in a particular project. In some cases, the analysis may conclude that free energy calculations will not be feasible for the proposed problem.
Here, by ``cost'', we refer not just to financial cost of the calculations relative to experiments, but also time -- can the calculations be run faster than experiments are done? How will the relevant resource and opportunity costs factor in? Both computation and experiment require human time, supplies (of different sorts), and equipment. In the extreme limit, for example, it would not make sense to spend a month running a binding free energy calculation if the equivalent experiment could be done in a day with resources already on hand. Such issues should be considered before deciding to conduct binding free energy calculations.

\subsection{Is an exploratory study what I want?}
\label{subsec:exploration}
An additional consideration is how much is known about your particular
target, ligand binding modes in the target, and any relevant motions
-- essentially, has it been studied enough to know whether it might be
suitable for free energy calculations? It is important to know if the system has hardly been studied, because should the initial calculations perform poorly, the effort may turn into an attempt to understand the relevant sampling, force field, or system preparation problems.

If you are unsure whether your project is feasible, as mentioned above, one recommended option is to conduct a short exploratory study to assess tractability for a small
number of ligands. This can be sufficient to get an initial
idea of feasibility and accuracy of the calculations for the
proposed target~\cite{schindler2020largescale}.

Many practitioners expect alchemical methods to provide valuable guidance for drug discovery, and to exhibit accuracy superior to most alternative approaches for suitable targets~\cite{kuhn2017prospective}. Successful application in industry may require considerable knowledge of the ``domain of applicability'' of free energy calculations -- where they work well and where they will not~\cite{sherborne2016collaborating}. Successful application also requires robust protocols for preparing, submitting and analysing alchemical calculations. In this regard, the issues mentioned in the previous section such as understanding the suitability and timescales to capture the structure activity relationships (SAR), and performing up-front tests of performance are all relevant to drug discovery applications. Without venturing too far into details of system setup, which is beyond the scope of this article, we highlight some critical factors affecting accuracy and successful application. 

\subsection{Capturing experimental conditions}
\label{subsec:exp_condition}
The calculations aim to capture the alchemical change from one ligand to another as accurately as possible. Therefore, it is necessary to consider details of the experimental setup, such as pH. Biological assays are usually run at neutral pH but this is not always the case. For example, some enzymes exhibit pH-dependent activity and assays may thus be done in conditions other than neutral pH. Therefore, computational protein and ligand preparation protocols should reflect experimental pH. 

The formal charge and/or tautomeric state of the small molecules can change within a series of analogs, necessitating care in treatment. Additionally, medicinal chemistry efforts might deliberately modify the pKa of a series to modify drug properties, requiring explicit efforts to incorporate these changes into alchemical calculations.

To ensure modeling matches experiment, we also need to accurately prepare and simulate the same system -- which requires understanding what protein construct is used in the bioassay. For instance, does the X-ray structure that is to be used for the calculations match the construct used for screening (i.e. only the catalytic domain vs. full length, monomer vs. dimer, etc.)~\cite{perez-benito2018predicting}? Also, were certain co-factors or partner proteins required in the bioassay? 

\subsection{Is my binding mode accurate?}
\tocsubsectioncomment{@Volunteer: Seems like this section is partly duplicated (e.g. "Are you prepared to deal with any binding mode challenges?" in part 1). @Volunteer to tidy this up, moving appropriate information to first article and focussing here on challenges in a high-throughput setting, e.g. should I use multiple binding poses from docking? How should I select them?}
As also mentioned, good performance of alchemical calculations requires an accurate representation of the ligand binding mode, usually from a high quality X-ray crystal structure. If more than one structure is available, the modeler should pay attention to choose the most suitable. The quality of the structure can be a concern, and the reader is referred to work of Warren et al. for a detailed discussion of choosing optimal structures for structure-based modeling~\cite{warren2012essential}.

It is also useful to study the structure activity relationship and understand the expected impact of any mutations on the binding site, such as whether side chain movement in the protein will be required, and whether there is evidence of this in any alternative X-ray structures of the same protein. Often, only one protein and water configuration is used for a series of alchemical calculations, so this needs to be capable of accommodating the smallest through to largest ligands in a way that allows stable and well behaved simulations. This can provide a practical limit on the alchemical changes that are feasible, though a simple work-around can be to separate compounds into sub-series for different calculations. 

If multiple structures are available there is some evidence the higher affinity complex can give better match to experiment~\cite{perez-benito2019predicting}, at least in some cases. However, ligands and proteins can also undergo unexpected changes in binding mode for related ligands, which can make these issues more complex to deal with~\cite{mey2016blinded}.

\subsection{Input setup and scale of calculations}
In a drug discovery setting it is normal to consider dozens (or more) of ligands and it is necessary to align them in the binding site. There is no detailed study of how different alignment approaches may affect results, but the user should be aware of some practical considerations. Tools are available to compare the ligands and build the combined topologies that define the changes between one ligand and another~\cite{loeffler2015fesetup,hedges2019biosimspace,gapsys2015pmx}. In simple terms, providing poor alignment to these tools will make this job harder. Docking with restraints is often beneficial in this regard. Particularly, fixing the 3D spatial position of the scaffold using maximal common substructure (MCSS) restrained docking can help provide well aligned input for the topology generation. Nevertheless, in this case careful attention is still needed to ensure consistency of alignment for identical substituents. Another alternative is to manually edit the same core and add/modify the changing substituents. This provides assurances that coordinates for the non-perturbed portion of the structure remain identical and aromatic substituents, for instance, have consistent dihedral angles. However, it is not feasible for many compounds and therefore automation is desirable. 

Finally, the role of water in ligand binding is not always well understood and it can be crucial to capture the changes in binding site solvation during ligand binding. Can crystallographic waters be retained? Do they clash with some of the larger ligands used in the alchemical perturbation? See Sec.~\ref{subsec:binding} for different strategies that can be applied to dealing with waters. Generally, before launching large numbers of alchemical free energy calculations it is always recommended to test the system using classical MD simulations and limited numbers of alchemical perturbations. Metrics such as ligand and protein RMSD and RMSF can be inspected, along with visual inspection of simulations, to ensure the system is stable and likely to be suitable for alchemical calculations. 

Running binding free energy calculations in a drug discovery application will typically require the use of software or tools to facilitate the large number of calculations. Commercial implementations such as FEP+, OpenEye Tools, or Flare allow for a fast setup and deployment to GPU hardware in minutes, but may have limited ability to customize calculations~\cite{wang2015accurate,kuhn2020assessment}. Commercial tools can be expensive in some cases, but non-commercial tools are becoming more straight forward to use to run alchemical free energy calculations~\cite{gapsys2015pmx, loeffler2015fesetup, song2019using, gapsys2020large, jespers2019qligfep, hedges2019biosimspace, kuhn2020assessment}.

For relative free energy calculations, various graph topologies or maps of calculations are possible, and choices may depend on the target application. For instance, if the goal is to accurately assess the relative binding energy of a small number of compounds, possibly with challenging syntheses, the map of perturbations should contain as many connections between compounds as affordable. However, when running calculations on hundreds of compounds a so called \emph{star-map} (see Fig.~\ref{fig:fig_types_of_networks}\textbf{A}) can be used that just contains one connection per compound: perturbing every compound to a central ligand, typically the crystal structure ligand~\cite{konze2019reactionbased}. In this way the top-ranking examples can be readily identified and submitted to additional calculations in a second round. Alternatively, if the goal is to achieve the smallest possible error with minimal computational expense, certain graph topologies provide benefits~\cite{yang2020optimal, xu2019optimal}


\subsection{Making predictions, understanding errors}
\label{subsec:predictions}
For prospective drug discovery applications there are several other considerations including understanding likely errors and taking selection bias into account. 

It is crucial when proposing compounds for synthesis to have some idea of the underlying error or uncertainty in the predictions. A retrospective assessment can give an indication of prospective performance for similar molecules~\cite{ciordia2016application}. Beyond this, several parameters provide useful indicators of performance. For example error estimates provided by free energy estimators that are too large can highlight poorly converged simulations~\cite{perez-benito2019predicting}. Hysteresis, either within cycles in the perturbation network or between forward and backward perturbations can be checked~\cite{wang2013modeling} to indicate problematic perturbations involved in cycles connecting many compounds (See also Secs.~\ref{sec:relative-fe-protocol} and~\ref{sec:are-they-good}). Once synthesis and testing of compounds is complete a standard strategy is to look back at how the calculations performed. In this regard it is important to consider the issue of selection bias upfront. It is tempting to only synthesize the compounds predicted to be most active, thus a narrow range of calculated activity is tested that imposes limits on the statistical assessment of performance, ideally example molecules from across the range of predicted activity can be assessed or corrections can be applied based on previous recommendations~\cite{robert2017critical}. For a more detailed discussion on checking the robustness of your alchemical free energy calculation see also Sec.~\ref{sec:are-they-good}.

In summary, the successful use of alchemical calculations, particularly for drug discovery, requires working in the domain of applicability, using a high quality X-ray structure of the target bound to compounds in the series, and testing the approach retrospectively to ensure the system setup is well-behaved. Always assess your confidence in the resulting predictions and communicate this when discussing with experimentalists. Consider performing repeat calculations for at least some of the perturbations in the study. 
 There are many accounts of success of alchemical calculations, the methods show good performance towards the goal of binding free energy prediction. However, it is important to have realistic expectations. 

Structure based drug design projects are often capable of improving potency relatively quickly, even with only limited application of computational approaches and the range of activity narrows to just two-to-three log units. It may seem hard to have impact with substantially different, more potent, stand-out compounds in this scenario, but binding free energy predictions can still be extremely useful for ensuring activity is maintained as other properties are optimized. An interesting cost benefit analysis has shown the value of activity prediction, see discussion above and articles such as~\cite{mobley2012perspective}. 
From a drug discovery point of view, alchemical calculations are expanding their domain of applicability, and there are reports of success using homology models~\cite{cappel2016relative} and GPCRs~\cite{deflorian2020accurate,lenselink2016predicting} for instance, as well as enabling charge change and scaffold hopping~\cite{chen2018accurate, wang2017accurate}, but these systems are undoubtedly more difficult. In the meantime, use cases are expanding to resistance prediction, selectivity prediction , solubility prediction – an exciting future for alchemical calculations~\cite{hauser2018predicting, albanese2020structure, mondal2019free}. 


\section{\tocorange{Large-Scale Simulation Planning}}
\label{sec:large_scale_planning}
\tocsectioncomment{Possibly add discussion of methods which are not easily characterised as single/ multi e.g. lambda dynamics? Maybe a better distinction is calculations where we are interested in more than two end states.}
\tocsectioncomment{@OpenFE team to add discussion of how to run and adaptively update perturbation networks.}
\tocsectioncomment{Possibly add discussion of different protocols, especially active learning. Best practices may not be well established but many companies are running at scale.}
\tocsectioncomment{Discussion of merits of ABFE/ RBFE for virtual screening? See @Gary Tresadern comment from first meeting - lots of discussion around ABFE calculations for virtual screening.}

\paragraph{Study design}
When planning a large scale prospective application, it is likely that the main objective is identification of novel high affinity binders. This goal also dictates the overall planning of calculation campaign: in this scenario it is not necessary to obtain an accurate binding free energy difference for each compound, but rather quickly filter out non-binders and weak binders, and focus the computational effort on the promising candidates. One approach for such a study, is to design a two step protocol: (i) FEC using short simulation times, ligands connected in a starmap configuration. This step is meant to filter out a large portion of weak binders: even if free energy estimates for each edge are not well converged, non-binders and weak binding affinities will be identified; (ii) standard FEC protocol with an optimal ligand connection map to obtain accurate free energy differences.

In more detail, simulation planning for a standard FEC can be conceptualized as a three-component framework. Starting, the process involves identifying all mappings of the involved molecules (e.g. atom mappings), which define the structural relationships and transformations between molecule A and molecule B. Subsequently, these changes, along with their shared structural elements, are evaluated by estimating the difficulty of the transformations usually with predefined scoring functions. The final step entails constructing the perturbation graph using the scores from the prior step, which serves as a fundamental tool setting up a simulation campaign.

\paragraph{Atom mappings}
For minor molecular transformations, like in most large-scale approaches, single-coordinate set approaches are typically utilized due to their relatively low computational cost. These methods necessitate atom mappings to ensure their effective application. In large-scale implementations, the efficiency and robustness of automated mapping techniques are critical factors in these endavors.

%SIS
Subgraph isomorphism solver (SIS)-based maximum common substructure (MCSS) search methods currently represent the most widely used approach for addressing atom mapping challenges. Several cheminformatics tools implementing these solutions are readily available, including pmx~\cite{gapsys2015pmx}, LOMAP~\cite{liu2013lead}, FESetup~\cite{loeffler2015fesetup}, ProtoCaller~\cite{suruzhon2020protocaller}, and SMArt~\cite{petrov2021perturbation}.

These methods exhibit high accuracy in processing topological 2D information. However, hybrid approaches such as pmx~\cite{gapsys2015pmx} and LOMAP~\cite{liu2013lead}, which incorporate 3D structural data, enhance robustness in stereochemical considerations and molecular alignment, requiring well-prepared input coordinates. Regarding computational efficiency, SIS solvers must contend with the inherent complexity of solving an NP-complete problem~\cite{raymond2002maximum, Duesbury2018Comparison}. The use of an initial MCSS seed can mitigate this computational burden~\cite{raymond2002maximum}.

% Geometry
An alternative to SIS-based MCSS methods is geometric bipartite matching for atom mapping, as implemented in tools such as pmx~\cite{gapsys2015pmx} and Kartograf~\cite{ries2024kartograf}. These algorithms enable rapid mappings due to their reduced computational complexity ($O(N) = N^3$), provided that well-aligned input geometries are available~\cite{ries2024kartograf}, through e.g. restraint-docking or prior-alignment. To accommodate topological variations, Kartograf applies a subsequent filtering step following the 3D mapping process.

% Short discussion of robustness and speed
Both mapping approaches present distinct advantages and limitations, each associated with specific prerequisites. Optimizing the robustness, and ignoring computational effort (e.g. mitigated by parallelization), it may be beneficial to employ both methods and implement a scoring mechanism to evaluate their performance. Most mappings are expected to be highly similar, this strategy could enhance robustness in the mapping process.

In terms of computational efficiency, the choice between methods largely depends on input conditions. If molecular structures are pre-aligned, the geometric approach offers a substantial speed advantage. The magnitude of the speed advantage is dependent on the number of mappings required and the number of atoms to be considered. Here we want to exemplify the effect by using the example of \textit{Ries et al.} calculating all-to-all mappings for given sets of molecules. The first example was a small set of 14 molecules and an average $38.6$ atoms per molecule; both approaches needed only $3~s$ to calculate the all-to-all mappings. A more challenging dataset with 16 molecules and an average of $74$ atoms per molecule increased the calculation duration to $26~s$ for the SIS based approach with LOMAP and $8~s$ for the geometric approach with Kartograf. Finally, using the double amount of molecules leads to a significant difference of $58~s$ for the geometric approach and $11~min$ and $16~s$ for the SIS based approach, indicating the algorithmic complexity difference. The complexity, however, does not only scale with the number of molecules. The last example of \textit{Ries et al.}  tries to put the number of atoms to an \textit{extreme} using a protein, with a very large number of atoms ($9349$ atoms) and mutates one residue, leading to two different molecules. This challenge is usually not addressed as a whole with SIS-algorithms, but chunked down into smaller sub-problems, like mappings per residue. However, the impact of the number of atoms on the computational efficiency can be well observed here. The problem was solved with the geometric approach in $2~s$. The SIS-based approach was stopped after $4~h$. \cite{ries2024kartograf} From this example, it becomes clear that for larger datasets the mapping problem becomes comparably large and starts to grow to a significant factor even in comparison to the simulation time.

Conversely, when ligands lack predefined 3D coordinates, the SIS-based methods provide an easy solution, allowing coordinate generation at a later stage. This nuanced selection process ensures optimal performance based on the specific characteristics of the molecular system under investigation. 

In combination with a suitable mapping scoring function the next steps is to build a pertubation map.

\paragraph{Perturbation maps}
For RBFE campaigns with more than two ligands in the input series a \textit{perturbation map} or \textit{-network} must be generated: this is simply a set of data that describe which transformations will be executed between the ligands (referred to as \textit{edges}). ~\cite{liu2013lead} Heuristics have shown the more connected the perturbation network the higher the free energy prediction accuracy versus experimental measures. Running a fully-connected network (i.e. simulate transformations between \textit{all} ligands in the campaign) is typically considered too computationally expensive and may not be suited optimally with current estimators such as MLE (\ref{subsec:uncertainty}).~\cite{scheen22data} Several styles of network designs have been proposed in recent years, although no single method seems to consistently outperform all others.~\cite{ries2024Konnektor} There exist several methods for optimization of network structure while minimizing the number of perturbations that need to be computed, reducing the resulting computational cost at a minimal decrease in accuracy ~\cite{yang2020optimal,xu2019optimal,Pitman2023HiMap}. Sometimes - depending on the RBFE implementation - the introduction of intermediate ligands that are not part of the original congeneric series can be helpful for avoiding challenging transformations such as ring breaking or transformations that would otherwise result in large numbers of atoms being inserted or deleted.~\cite{schoenmaker2025imerge} Some commercial tools have well-calibrated underlying heuristics to plan these network designs but may fail with complicated input datasets, thus requiring manual user validation, in particular when dealing with chiral compounds. 

\begin{figure}
    \includegraphics[width=0.95\columnwidth]{figures/fig6_types_of_networks/Figure.pdf}
    \caption{\textbf{Examples of perturbation networks} (\textbf{A}) Star shaped network with the crystal structure in the center. (\textbf{B}) Network with cycle closures (see more on this in Sec.~\ref{sec:are-they-good}). Arrows indicate the direction of the perturbation. Fully converged binding free energy calculations yield binding free energy changes which sum to zero around any closed cycle, and non-closing cycles that do not equal zero to within combined error can indicate potential sampling problems or protocol issues. Here in (B), green cycles indicate cycles with hypothetically good cycle closure, red those with poor cycle closure. The red arrow indicates a poorly converged simulation that would give rise to bad cycle closures. The diamond indicates the use of a crystallographic binding mode.}
    \label{fig:fig_types_of_networks}
\end{figure} 

In some cases, when dealing with for example very large datasets that would benefit from rougher initial free energy ranking or in cases where perturbations would be rather large, a star shaped network as seen in Fig.~\ref{fig:fig_types_of_networks} \textbf{A} is used. However, adding redundancy into the network means that a better error analysis can be carried out by analyzing cycle closure errors as discussed in sec.~\ref{sec:are-they-good}, with an example given in Fig.~\ref{fig:fig_types_of_networks}\textbf{B}.


Methods from experimental design have been applied to the construction of perturbation maps. Yang et al.~\cite{yang2020optimal} showed how to optimize the perturbation map by selecting a fixed number of calculations from the pairwise perturbations so that the resulting set of calculations minimize the total variance. Xu~\cite{xu2019optimal} showed how to optimize the perturbation map by allocating different amounts of simulation time to different pairwise perturbations so as to minimize the total variance, given the total simulation time of all the perturbation calculations. Both approaches lead to substantial reduction in the statistical error of the estimated free energies. 

There is a growing trend for virtual screens to process increasingly large datasets—ranging from millions to billions of compounds—driven by the availability of scalable cloud computing resources and make-on-demand compound libraries. Absolute Binding Free Energy (ABFE) calculations are increasingly being adopted as a late-stage filter in virtual screening campaigns. To maximize enrichment in hit compounds identified from libraries generated through docking, ABFE should ideally be deployed on large compound datasets (hundreds to tens of thousands of molecules).
However, because ABFE is generally more computationally expensive to converge than Relative Binding Free Energy (RBFE) calculations, large-scale ABFE campaigns are currently undertaken predominantly by well-resourced companies. Consequently, there has been limited reporting from academic groups to guide best practices in this area.
Specific challenges have been reported in the use of algorithms that automate the selection of protein–ligand translational-orientational restraints. For example, in the widely used ‘Boresch restraints’ scheme, it is well known that restraint parameters should be selected to minimize the risk of collinear angles between restrained atoms.~\cite{Wu2025} Heuristics, based on short molecular dynamics (MD) simulations performed prior to ABFE calculations, have been proposed to address this.~\cite{Heinzelmann2024,Hedges2023} Given the high computational costs, some groups have suggested using relatively short ABFE simulations to drive active learning cycles in virtual screening.~\cite{CrivelliDecker2024} However, more research is needed to determine whether robust surrogate estimators can be derived from noisy, short-run ABFE outputs.
Another unresolved issue concerns the accuracy achievable with ABFE calculations. Many published benchmarks have focused on congeneric series originally designed to validate RBFE protocols. These may represent favorable cases for ABFE as well, due to greater cancellation of systematic errors in protein–ligand interactions, as well as unambiguous binding pose, compared to cases involving structurally diverse scaffolds.\cite{Merz2010} Furthermore, benchmarks based on enrichment rates may be misleading, as they also reflect the accuracy of the input poses generated by docking.
For some targets, long-timescale ABFE calculations yield binding free energy estimates consistent with experimental data. However, calculated binding free energies are often overestimated. It has been suggested that this overestimation may stem from a systematic offset due to protein reorganization free energy contributions, which are not fully captured on the timescales of typical ABFE simulations.~\cite{Chen2023} While methods to take protein apo-holo reorganization into account exist~\cite{khalak2021absdg,fajer2023protreorg}, it may become challenging to apply them in a virtual screening scenario where compounds of diverse chemistry may require considering different protein holo states. Further work is needed to assess how this contribution varies across chemically diverse scaffolds and different protein targets.


\section{\tocred{How should I automate my calculations}}
\label{sec:automation}
\tocsectioncomment{Include e.g. automated selection of where to concentrate sampling time e.g. https://pubs.acs.org/doi/10.1021/acs.jctc.1c00703, automated selection of restraints for ABFE, link with discussion of available tools?}
\tocsectioncomment{@OpenFE team well placed to contribute. Discuss tools like alchemiscale? Discuss e.g. integration with REINVENT/ Maize for active learning?
@Vytas Gapsys}

Application of free energy calculations (FEC) on a large scale, naturally, requires automation of the workflow. For a smaller scale explorations, often related to method development in an academic setting, a usual approach is tying together the individual steps with scripts. This, however, often proves to be error prone, requires human intervention, lacks transferrability and is difficult to upscale. With the individual components of the FEC workflow becoming more robust, also, the solutions to automate the full pipeline started to emerge.

FESetup~\cite{loeffler2015fesetup} was one of the earliest FEC automation efforts: it allowed ligand parameterization, protein preparation, atom mapping, topology generation, and prepared simulation boxes. Nowadays, the more advanced toolkits, also provide functionality of executing the simulations by dispatching, monitoring and, if needed, resubmitting jobs to a cluster or HPC facility. Some examples of automated workflows include alchemiscale~\cite{alchemiscale}, Icolos~\cite{moore2023icolos} and its successor Maize~\cite{lohr2024maize}. Alternatively, one may use building blocks from one of the FE calculation packages, e.g. OpenFE~\cite{openfe}, BioSimSpace~\cite{hedges2019biosimspace}, pmx~\cite{gapsys2015pmx}, and connect them by means of a workflow manager such as Luigi~\cite{luigi}, Apache Airflow~\cite{airflow} or KNIME~\cite{knime}.

A few words on active learning combined with FEC. Unfinished...

\section{\tocorange{Data analysis}}
\label{sec:data_ana}

\subsection{Uncertainty estimation}
\tocsubsectioncomment{@Agastya P Bhati/ Peter Coveney to cover uncertainty estimation for multiple simulations? Move cycle closure etc sections here.}
\label{subsec:uncertainty}

\paragraph{Cycle closure error}
Relative free energy calculations, which compute the change in free energy on making a change to a molecule (e.g. adding a functional group to a ligand) may provide an additional opportunity for error/consistency checking. Particularly, such calculations are often done to span a graph or tree of free energy calculations~\cite{xu2019optimal,wang2013modeling,liu2013lead}. In some cases the free energy change to go between molecules A and B can be obtained via multiple transformation pathways. This allows a type of consistency checking where we assess how much the free energy change for that transformation in practice differs from equivalence. 

Significant deviations of agreement from the same transformation by different routes typically indicate insufficient configurational sampling along the lambda schedule of one or more of the transformations involved. This approach may be generalised to sets of connected transformations given the requirement that the sum of free energy changes along edges of a closed cycle should be zero. This analysis is called ``cycle closure''. In practice, such thermodynamic cycles do not actually sum to zero, and deviations become increasingly large as the size of the cycle increases owing to propagation of error. Though no firm guidelines have emerged, it may be judicious to perform additional configurational sampling along edges of a network that are involved in cycles closing poorly. This may be done by extending the duration of simulations, or by averaging free energy changes over multiple repeats. The latter approach may yield more reproducible free energy changes, but at the expense of a stronger bias on the estimated free energies due to repeated use of the same input coordinates.

A scheme to reduce cycle closure errors is used in FEP+ whereby calculated free energy changes along the nodes of the network are re-sampled assuming estimates of the calculated free energy change along a node may be obtained from a Gaussian distribution centered on the estimated free energy change and with a standard deviation equal to the estimated standard deviation of the free energy change. The procedure then uses a maximum likelihood method to find new sets of free energy changes that minimize cycle closure errors~\cite{wang2013modeling}. An alternative approach computes the free energy change between a target and reference compound as a weighted average over all unique paths in the network, with the weights derived from the propagated uncertainties of each node~\cite{mey2016blinded}. Approaches as illustrated by Yang et al. for perturbation map design can also be used to compute relative free energies between target and reference compounds~\cite{yang2020optimal}.

\subsection{Best practices for reporting data }
\label{sec:plot_data}
\tocsubsectioncomment{@OpenFE team/ @Jenke Scheen/ Volunteers to expand on utility/ limitations of common metrics. Also see @Michael Gilson's GitHub issue.}
Following best practices for data generation and their analysis does not mean that data is reported in the optimal way. As a practitioner of alchemical free energy simulations you also should use best practices for reporting and plotting your results. We encourage the following standard set of analyses and ways to represent data. Some distinctions can be made between statistics that report how accurate and reproducible your results are to a ground-truth experiment, and how useful a method might be in an applied setting. For the case of relative free energy calculations, results might be reported either per-edge, as DDGs, or as the MLE-augmented DG results. Relative results (and outliers in this regime) can be more indicative of edge-based errors, whereas outliers in DG could be more indicative of a node-based error, such as a forcefield error for particular ligands. For relative free energy results, it is best practice to plot both.


\paragraph{Statistics to include in reporting data}
As with any modelling technique, misuse of statistical analysis can skew the perception of how well models perform in free energy predictions. First, error estimates should always be included on your predictions in whatever form you present your data (scatterplots, barplots, etc; see next paragraph). We recommend performing triplicates of your predictions at minimum, with starting points that are expected to be uncorrelated, to ensure some measure of reliability in your data. This replication may seem excessive, but uncertainty estimates often underestimate the true statistical uncertainty. Where performing multiple replicas of the simulation is not possible, an error estimate from e.g. MBAR can be used, though bearing in mind this is likely an underestimated error. 

As alchemical free energy methods are used in drug discovery to quantify and rationalise structure activity relationships (SAR), the models ability to (a) correlate well with experiment and (b) rank-order the molecules by affinity, should both be computed. Conventionally, this means including an R\textsuperscript{2} (or Pearson's R), where $R=+1$ means high correlation, $R=0$ means no correlation, and $R=-1$ means high anti-correlation) and a Kendall \texttau{} (with perfect ranking agreement when \texttau=1 and perfect disagreement when \texttau=-1) metric in your results. Additionally, practitioners may choose to include a Spearman \textrho{} as well. Brown et al.~\cite{brown2009healthy} have provided a useful analysis in terms of upper bounds of expected possible correlations between experiment and computation with a given potency range for the compounds. For example, for potency ranges of 2 log units it would be impossible to get a higher correlation in R than 0.8 because of experimental uncertainties~\cite{brown2009healthy}. What often is neglected to include is an error analysis on correlation statistics that arise from the errors of both experimental and computed data. One way to include such error analysis for correlation metrics is using bootstrapping on the datasets. The D3R community challenges follows best practices on their data evaluation with readily available python scripts online~\cite{2018drugdata}, based on work by Pat Walters~\cite{walters2013what}. Other analysis software also provide similar functionality for bootstrapping datasets~\cite{antonia2019michellab}. 

Mean unsigned error (MUE, also called mean absolute error/MAE) is another key statistic to include in your results. Even though some models' near-perfect correlation and ranking statistics might suggest excellent accuracy, MUE values can still have errors of multiple kcal/mol, providing important additional insight into performance. Furthermore, MUE allows for unbiased comparisons between predictive models as it is less sensitive to dataset size. Other metrics such as Gaussian Random Affinity Model (GRAM)~\cite{cui2020gram}, Predictive Interval (PI) and Relative Absolute Error (RAE), attempt to correct for the inherent potency range of a dataset, which can aid in comparing success between different targets. We recommend further reading on evaluation of computational models~\cite{jain2008recommendations, walters2013what, brown2009healthy, walterthoughts}.

Reporting the results of relative free energy calculations requires care. As shown in Fig.~\ref{fig:fig_types_of_networks}, relative free energies can be performed arbitrarily as a forward or a reverse process, and thus relative free energies may be reported as either positively or negatively valued. The consequence of the two possible signs for relative free energies is that correlation statistics (such as Pearson's R and Kendall \texttau{}) can be skewed depending on which sign is analysed. The issue of this inconsistency can be circumvented by either plotting all datapoints within a consistent quadrant~\cite{perez-benito2019predicting}, or by avoiding the use of correlation statistics for assessment of relative free energy calculations and instead measuring accuracy using RMSE and MUE, which are unaffected by choice of sign. Issues can also arise with relative free energy calculations if different reference ligands are used as the centerpoint by which to take as the ground truth value to shift other results relative to. It is recommended to instead use the mean-centered experimental data of the set for consistency in reporting\cite{gathiaka2016d3r}.


\paragraph{Presenting your data}
As essentially all alchemical free energy prediction schemes are regression problems, the preferred type of plot is a scatter plot (see Fig.~\ref{fig:scatterplot_analysis}). Most alchemical free energy projects will look at 10-50 ligands. Any study with \textless10 ligands is more suitable for bar plots (with inclusion of error bars), and is unlikely to provide meaningful statistics. Any study with \textgreater50 ligands typically contains multiple protein targets to which alchemical free energies may perform better on some targets than others. Because of this, it is bad practice to place multiple datasets on the same plot as this can suggest high model accuracy even though the individual models perform less well~\cite{walterthoughts}.

\begin{figure}
  \includegraphics[width=0.95\linewidth]{figures/fig13_analysis_practices/Figure.png}
  \caption{\textbf{An example of recommended practices for graphing alchemical free energy predictions.} This figure shows the relation between predicted and experimentally-determined Gibbs free energy in kcal/mol with standard errors as error bars as a relative experiment (\textbf{A}) and absolute (\textbf{B}). The dark and light-orange regions depict the 1- and 2-kcal/mol confidence bounds. Statistical metrics for the data are reported, with 95\% confidence intervals determined by bootstrapping analysis. Extra care should be taken when investigating potential outliers further. \textbf{C} demonstrates an example of an iLLE plot to be presented in a prospective setting.}
   \label{fig:scatterplot_analysis}
\end{figure}

As we are interested mainly in the linear relationship between the alchemical free energy predictions and the experimentally-determined affinity values, plots should be depicted with the same range on both axes (i.e. $x=y$) with a 1:1 aspect ratio, with units for both experiment and simulation converted to be the same. If this skews the plot to a point where it is difficult to read of information, using the same dimensions, such that e.g. 1 cm is 1 kcal/mol is acceptable. Furthermore, bounds should be depicted for the 1- and 2-kcal/mol confidence regions. These regions can serve as tools to communicate your model performance: any predictions inside the 1 kcal/mol region can be seen as highly reliable, any predictions inside the 2 kcal/mol region should be seen as somewhat reliable, and any predictions outside the confidence regions should be expected to be unreliable and handled as outliers. In a drug discovery context, this type of data depiction may suggest the reliability of alchemical FE predictions in the project, and can give an idea of how trustworthy predictions can be for synthesis ideas. It is also recommended to included experimental error bars in all plots. 

Best-practices for reporting predicted affinities retrospectively have been outlined, however using free energy methods prospectively where possibly none, one or only a few experimental datapoints for the set have associated energies might be available can be more difficult if any supporting statistics will not be possible or meaningful for a small set. Lipohilic ligand effciency (LLE or LipE) plots are typically used in drug discovery for understanding the relationship between lipophilic-driven binding affinity for series of compounds. Predicted or measured LogD or LogP on the x-axis and measured potency on the y-axis, typically with diagonal y=x+C lines used to indicate where compounds are achieving better/worse binding due to specific or polar interactions. Using \textit{in silico} iLLE plots, with predicted affinities and predicted LogP or LogD can be helpful to visually present free energy results with limited experimental data.

An example of a best practice scatter comparison between computed and experimental values is shown in Fig.~\ref{fig:scatterplot_analysis}A-C for relative, absolute and LogP reporting, respectively. These highlight outliers, error bars and confidence intervals correctly. The data for these plots are artificially generated for illustration purposes.


\section{\tocred{Unsettled Practices and Current Limitations}}
\tocsectioncomment{@Everyone to contribute to section on unsettled practices/ current limitiations, as suggested by John Chodera.}
\label{sec:unsettled}

\subsection{Unsettled practices}
\tocsubsubsectioncomment{Include discussion of active learning/ fast ABFE for virtual screening?}

In general, typical free energy workflows are best suited for when true ligand binding modes are well-known and available in advance, which of course poses challenges when such methods are applied prospectively. Typically for relative free energy calculations, ligands in a congeneric or related series are assumed to have similar/the same binding mode, preserving the location of any shared scaffold, though this will not always be the case. In other situations, practitioners may wish to generate ligand binding modes using fast and approximate methods such as docking, which can impact the accuracy of resulting free energy calculations since such binding modes may be less than reliable. 

While the binding mode issue alone poses challenges, it also impacts overall free energy workflows. In particular, for relative free energy calculations (which are the most broadly used in large scale applications), pose consistency affects how free energy calculations should be planned (i.e. the issue of ligand perturbation maps, and also that of atom mapping). Related ligands sharing a consistent binding mode constitute an easier perturbation than related ligands with dissimilar binding modes, so the choice of pose generation approach and the confidence in provided poses affects downstream ligand perturbation network and atom mapping. Best practices are not well understood here, nor thoroughly explored, though some choices will clearly be better than others -- for example, if input ligand poses are carefully curated, shared across ligands, and likely accurate in 3D, then atom mapping approaches that use 3D, like Kartograf~\cite{}, will likely provide superior results, but if poses are more dissimilar and not as well curated in 3D, alternate approaches may be superior.  Such choices may also interact with the choice of perturbation planning algorithm in a way which is not yet well understood. 

Similar issues may affect the optimal choice of absolute vs. relative free energy calculations in typical applications, e.g. when a ligand series is highly related and typically shares a common binding mode (within some tolerance) relative calculations may yield good performance, but as binding mode inconsistency grows, absolute calculations may offer advantages for perturbations that change the binding mode -- even if the ligands are highly structurally related. 

Best practices for reporting metrics are also evolving. The metric \textit{Best N ligands} has been proposed to help understand if a method is particularly performative within the domain of interest. Christopher Bayly has suggested the use of \textit{Best N ligands} to capture if a method selects the true best molecules within the predicted best molecules, as a metric to reflect how likely you are to synthesise the most potent ligands with a budget allowing for \textit{N}. The metric is a specific case of Boltxmann-Enhanced Discrimination of Receiver Operating Characteristic Curve (BEDROC)\cite{swamidass2009influence}. For purposes of practical application, one likely cares more about your models performance at the higher-activity range of the spectrum vs. across the whole dynamic range; most drug designers would prefer a model that can classify non-/weak-binders and rank binders rather than a method that ranks non-/weak-binders and classifies binders. While the metric usefulness in an applied setting, poorer performance in a lower-ranked compounds could indicate issues in the method and understanding outliers is important for understanding domains-of-applicability or highlighting algorithmic limitations. Additionally, choice of \textit{N} could differ largely for the same target and ligands but different users.


\subsection{Current limitations}

\section{\tocred{Conclusion}}
\tocsectioncomment{@Volunteer to add.}
\label{sec:conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  Benchmark information  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\tocorange{Alchemical free energy datasets: an overview}}
% \tocsectioncomment{@Volunteers to update this section}
\label{sec:benchmark}
The quality of datasets used for method development, validation, and benchmarking is the determining factor for the reliability and reproducibility of alchemical free energy methods. Diverse, high-quality datasets that capture both structural and thermodynamic protein-ligand interaction data are essential for constructing robust benchmarks for alchemical free energy calculations. In this section, we provide a non-exhaustive overview of current alchemical free energy datasets that can serve as a starting point to assessing the performance of existing alchemical free energy approaches or to testing and benchmarking new methods. 

Community blind challenges have served as a rich source of free energy data and a powerful way for researchers to assess the prospective predictive utility of their methods. The Statistical Assessment of the Modeling of Proteins and Ligands (SAMPL) challenges, for example, have provided the free energy community with experimental structural and affinity data from synthetic supramolecular host-guest systems ~\cite{
amezcua_sampl9_2024, amezcua_overview_2022, amezcua_sampl7_2021, rizzi_overview_2018, yin_overview_2017, muddana_sampl4_2014}. These systems allow researchers to evaluate the predictive performance of their methods on relatively simple test cases due to their relatively small size and limited conformational flexibility. Similarly, the Drug Design Data Resource (D3R) Grand Challenges have made available protein-ligand crystal structures along with experimentally-measured affinities ~\cite{parks_d3r_2020, gaieb_d3r_2019, gaieb_d3r_2018, gathiaka_d3r_2016}. Of particular importance for alchemical free energy methods, these datasets sometimes include defined congeneric series that enable benchmarking of relative binding free energy methods. Additional blind challenges include CASP challenges ~\cite{gilson_assessment_2025} as well as the pan-coronavirus challenge (hosted by the Open Molecular Software Foundation, the AI-driven Structure-enabled Antiviral Platform, and Polaris) ~\cite{macdermott-opeskin_computational_2025}. In a field where subtle data leakage or hidden biases may inflate the apparent performance of an alchemical method, blind challenges remain essential for rigorously assessing their predictive power and generalizability. 

Several companies have made valuable datasets publicly available. Schr\"{o}dinger released an FEP benchmark dataset ~\cite{ross_maximal_2023} consisting of 54 individual targets and 1,237 protein-ligand pairs with affinities.  They used this dataset to evaluate the theoretical accuracy ceiling for binding free energy calculations. Merck KGaA also released a benchmark set with 8 targets and 264 protein-ligand pairs with affinities ~\cite{schindler_large-scale_2020}. They aggregated this from publicly available data and used it to assess the accuracy of their free energy calculations. These datasets, along with others released from industry sources, have become important resources for benchmarking alchemical methods. 

In recent years, datasets that include computationally-derived protein-ligand structures— such as those obtained through docking or co-folding—have become increasingly common. For instance, docked structures were used in the construction of BigBind ~\cite{brocidiacono_bigbind_2024}. BigBind starts with CrossDocked2020: a dataset built by clustering experimental protein-ligand complexes based on binding pocket similarity, and then augmenting the dataset by docking ligands into other similar pockets ~\cite{francoeur_three-dimensional_2020}. BigBind maps ChEMBL activity data to CrossDocked2020 to generate a dataset that pairs structures and affinities. This dataset is then used to develop a neural network-based classifier that distinguishes active and inactive compounds. Similarly, a template-based modeling approach was used to construct BindingNet—a dataset that augments experimental protein-ligand structures to include ligands with similar structure and known affinities to the same protein. This dataset has useful applications in affinity prediction and pose prediction tasks. Additionally, SandboxAQ recently introduced a dataset of over one million co-folded protein-ligand structures (generated using the Boltz-1x model) and paired affinities ~\cite{lemos_sair_2025}. Efforts are already demonstrating that augmented data can improve alchemical free energy predictions ~\cite{valsson_narrowing_2025}. 

Despite these extensive efforts, the need for high-quality, standardized datasets persists. While aggregating affinity data across different assays may seem like a powerful way to enhance the predictive power of alchemical tools, merging measurements from different assays introduces substantial noise and error, thus reducing the reliability of downstream predictions ~\cite{landrum_combining_2024}. There is a critical need for high-throughput affinity data generated from a single, standardized experimental source across a diverse set of protein targets. The field is progressing toward more systematic and reproducible approaches to generating protein-ligand benchmark datasets. Ongoing developments in this area can be tracked via the following resource: \url{https://github.com/openforcefield/FE-Benchmarks-Best-Practices}.

For a concise list of selected benchmark dataset, many of which were described above, along with their number of distinct protein targets and target-ligand complexes, please refer to Table~\ref{tab:benchmarks}.


\begin{table}
\caption{Selection of example datasets}
% \begin{tabular}{lr}
\begin{tabular}{p{4.5cm}p{3.5cm}}
\textbf{Dataset} & \textbf{\shortstack{Targets;\\Target-Ligand Structures\\ and Affinities}} \\
\hline
\multicolumn{2}{|c|}{D3R Grand Challenges~\cite{noauthor_d3r_nodate}} \\
\hline
GC4~\cite{parks_d3r_2020} & \hspace{1cm} 2; 613 \\
GC3~\cite{gaieb_d3r_2019} & \hspace{1cm} 6; 429 \\
GC2~\cite{gaieb_d3r_2018} & \hspace{1cm} 1; 36 \\
GC2015~\cite{gathiaka_d3r_2016} & \hspace{1cm} 2; 18 \\
\hline
\multicolumn{2}{|c|}{SAMPL Challenges\textsuperscript{a}~\cite{noauthor_sampl_nodate}} \\
\hline
SAMPL9~\cite{amezcua_sampl9_2024} & \hspace{1cm} 3; 23 \\
SAMPL8~\cite{amezcua_overview_2022} & \hspace{1cm} 3; 17 \\
SAMPL7~\cite{amezcua_sampl7_2021} & \hspace{1cm} 3; 50 \\
SAMPL6~\cite{rizzi_overview_2018} & \hspace{1cm} 3; 30 \\
SAMPL5~\cite{yin_overview_2017} & \hspace{1cm} 3; 22 \\
SAMPL4~\cite{muddana_sampl4_2014} & \hspace{1cm} 2; 23 \\

\hline
\multicolumn{2}{|c|}{Additional Community Challenges} \\
\hline
CASP16  ~\cite{gilson_assessment_2025} & \hspace{1cm} 5; 140 \\
Pan-coronavirus dataset ~\cite{macdermott-opeskin_computational_2025} & \hspace{1cm} 2; 2,303 \\

\hline
\multicolumn{2}{|c|}{Additional Alchemical Datasets} \\
\hline
BindingNet v2* ~\cite{zhu_augmented_2025} & \hspace{1cm} 1,794; 689,796 \\
BigBind* ~\cite{brocidiacono_bigbind_2024} & \hspace{1cm} 1,107; 582,957 \\
Merck KGaA dataset~\cite{schindler_large-scale_2020} & \hspace{1cm} 8; 264 \\
PLINDER ~\cite{durairaj_plinder_2024} & \hspace{1cm} 11,154\textsuperscript{b}; 78,410 \\
PoseBusters ~\cite{buttenschoen_posebusters_2024} & \hspace{1cm} 308; 308\textsuperscript{\ddag}\\
Protein-ligand benchmark ~\cite{hahn_best_2022} & \hspace{1cm} 21; 559 \\
Ross et al. benchmark ~\cite{ross_maximal_2023} & \hspace{1cm} 54; 1,237 \\
Runs N' Poses ~\cite{skrinjar_have_2025} & \hspace{1cm} 2,585; 3,047\textsuperscript{\ddag}\\
SAIR* ~\cite{lemos_sair_2025} & \hspace{1cm} 5,149; 1,048,857 \\
sc-PDB ~\cite{desaphy_sc-pdb_2015} & \hspace{1cm} 3,678; 5,608\textsuperscript{\ddag}\\


\hline
\label{tab:benchmarks}
\end{tabular}
\vspace{0.5em}
\caption*{\footnotesize * Denotes datasets that are augmented with computational data, including docked structures or co-folded. \\
\textsuperscript{a} Denotes that targets are supramolecular hosts rather than proteins.\\
\textsuperscript{b} Distinct protein targets are identified using SCOP domains. Plinder draws data from over 100,000s PDB IDs.\\
\textsuperscript{\ddag} Denotes target-ligand affinities are not provided, only target-ligand structures are available.}
\end{table}

\section{\tocorange{Checklist}}
\tocsectioncomment{@Volunteer to update checklist once manuscript is nearing completion.}
\label{sec:checklist}
\begin{Checklists*}
\begin{checklist}{ Know what you want to simulate}
    \textbf{Initial questions you should ask before you set up an alchemical free energy calculation using molecular dynamics simulations}
\begin{itemize}
    \item Do I understand the biology, chemistry and physics of my system?
    \item Have I properly prepared my protein and ligand systems?
    \item Does my system contain any structures that require custom parameters?
    \item What simulation protocol will provide the most evidence to verify my hypothesis?
    \item Are the projected computational expense and runtime realistic for my scientific goals?
    \item Will my protocol be reproducible? 
    \item Will my statistics be reliable? If not, would more replicates solve the problem? 
    \item Can I open-source my data?
\end{itemize}
\end{checklist}

\begin{checklist}{Preparing your simulations}
\textbf{Steps to getting started setting up your alchemical free energy calculation}
\begin{itemize}
    \item Make sure you know why you have picked your (combination of) force field(s)
    \item Energy minimize your system
    \item Equilibrate your system properly with your choice of thermodynamic ensemble
    \item Check the stability of your system and whether it behaves the way you believe it should
\end{itemize}
\end{checklist}

\begin{checklist}{Running absolute simulations}
        \textbf{Steps to running your absolute alchemical free energy calculations}
\begin{itemize}
 \item Check your ligands have the same, biologically correct binding pose
        \item Make sure your \textlambda-scheduling is  appropriate
        \item Check if your ligands are discharging and decoupling correctly
        \item Set up your restraints correctly
        \item Make sure you subsample the data in your free energy estimation protocol
        \item Apply the appropriate correction terms
\end{itemize}
\end{checklist}

\begin{checklist}{Running relative simulations}
        \textbf{Steps to running your relative alchemical free energy calculations}
\begin{itemize}
   \item Check your ligands  have the same, biologically correct binding pose
        \item Make sure your $\lambda$-scheduling is set correctly
        \item Make sure your molecular transformations are realistic (1-5 heavy atoms for reliable computations)
        \item Generate a perturbation network by your method of choice; check whether you have enough cycle closures to check consistency in the results
        \item Check whether dummy atoms were assigned correctly
        \item Consider subsampling the data in your free energy estimation protocol
        \item Apply the 
        appropriate correction terms
\end{itemize}
\end{checklist}
\end{Checklists*}

%Analyis checklist
\begin{Checklists*}
\begin{checklist}{How do I know which simulations are unreliable?}
    \textbf{Situations suggesting your relative alchemical free energy calculations have not run properly (assuming absence of experimental affinities)}
        \begin{itemize}
                \item Standard error (\textsigma) should not be \textgreater1 kcal·mol$^{-1}$ 
    \item Simulated systems have not converged - trajectories should be manually checked for consistency; other methods such as generating RMSD plots are also recommended
    \newline\newline\textit{Relative:}
    \item If you observe hysteresis in perturbations and incorrect cycle closures
    \item Energy differences \textgreater$\sim$15 kcal$\cdot$mol$^{-1}$  are likely unreliable
    \newline\newline\textit{Absolute:}
    \item Energies \textless$\sim$-15 kcal$\cdot$mol$^{-1}$  are likely unreliable
    \item The ligand has not sampled most of the intended region after the decoupling step
    \item The ligand is drifting out of the intended region after the decoupling step
        \end{itemize}
\end{checklist}

\begin{checklist}{Why are they not reliable?}
    \textbf{Suggestions for finding out why your alchemical free energy calculations may not be reliable}
\begin{itemize}
    \item Check again whether dummy atoms were assigned correctly
    \item Inspect the trajectories across the $\lambda$-schedule (particularly the endpoints) for problems described in the text
    \item Inspect the overlap matrices for lack of overlap
\end{itemize}
\end{checklist}

\begin{checklist}{Data Analysis}
    \textbf{Steps to analyzing your output data correctly}
\begin{itemize}
    \item Make sure you have run enough replicates to ensure statistical reliability (\textgreater3)
    \item Compute both correlation and ranking coefficients and ranking statistics (e.g. r, \textrho, MUE and \texttau)
    \item Include error bars in all your visual analyses
\end{itemize}
\end{checklist}
\end{Checklists*}
\clearpage


\section*{Author Contributions}
%%%%%%%%%%%%%%%%
% This section mustt describe the actual contributions of
% author. Since this is an electronic-only journal, there is
% no length limit when you describe the authors' contributions,
% so we recommend describing what they actually did rather than
% simply categorizing them in a small number of
% predefined roles as might be done in other journals.
%
% See the policies ``Policies on Authorship'' section of https://livecoms.github.io
% for more information on deciding on authorship and author order.
%%%%%%%%%%%%%%%%
\textbf{ASJSM}: Coordinated the document, contributed to most sections, and co-designed Figs.~\ref{fig:fig_binding_thermodynamic_cycle},~\ref{fig:fig_topology},~\ref{fig:fig_mcss},~\ref{fig:fig_types_of_networks},~\ref{fig:fig_absolute_thermodynamic_cycle},~\ref{fig:scatterplot_analysis}, and created Figs.~\ref{fig:fig_what_is_lambda},~\ref{fig:fig_what_is_alchemy},~\ref{fig:overlap},~\ref{fig:pmf} and replotted~\ref{fig:automatic-equilibration-detection} and~\ref{fig:fig_types_of_networks}.\\
\textbf{BA}: Helped write the uncertainty estimation, stopping conditions, and output analysis sections and created figure ~\ref{fig:convergence_forward_reverse}.\\
\textbf{HBM} Contributed to Sec.~\ref{sec:plot_data} and Fig.~ \ref{fig:scatterplot_analysis} and helped edit the paper.\\
\textbf{JDC}: Wrote Sec.~\ref{sec:decorrelating-samples} and~\ref{sec:automatic-equilibration-detection} discussed structure and design of the whole document, suggested Figs.~\ref{fig:fig_what_is_alchemy} and~\ref{fig:fig_sampling_scheme}. \\
\textbf{DFH} Contributed to Sec.~\ref{sec:software} and helped edit the paper. \\
\textbf{MK}: Contributed to Sec.~\ref{sec:data_analysis}, provided the data for figure~\ref{fig:overlap}, compiled the dataset for Sec.~\ref{sec:benchmark} and helped edit the paper.\\
\textbf{JM}: Contributed to Sec.~\ref{subsec:reproducible},~\ref{sec:prerequisites},~\ref{sec:important_path},~\ref{subsec:estimators},~\ref{subsec:uncertainty}, and~\ref{sec:conclusion}\\
\textbf{DLM}: Contributed to the outline, drafted some of the sections, gave ideas on figures, and helped edit the paper.\\
\textbf{LNN}: Helped write the simulation length, stopping conditions, and information saving section. Edited and reviewed alchemical path section.\\
\textbf{SP} Wrote Sec.~\ref{sec:software}. \\
\textbf{AR}: Created figure~\ref{fig:freeenergytrajectories}, contributed to sections~\ref{sec:theory} and~\ref{sec:simulation_protocol_choice}, and helped edit the paper.\\
\textbf{JS}: Created Figs.~ \ref{fig:fig_what_is_alchemy},~\ref{fig:fig_binding_thermodynamic_cycle},~\ref{fig:fig_topology},~\ref{fig:fig_mcss},~\ref{fig:fig_absolute_thermodynamic_cycle},~\ref{fig:scatterplot_analysis}, and an initial draft of~\ref{fig:fig_types_of_networks}. Wrote Sec.~\ref{sec:plot_data}, the checklist Sec.~\ref{sec:checklist}, and contributed to general formatting discussions and editing.\\
\textbf{MRS}: Helped create figure~\ref{fig:fig_what_is_lambda}, wrote Sec.~\ref{sec:important_path} describing choices for alchemical pathways and parts of~\ref{sec:data_analysis} on the analysis for free energy calculations. Reviewed and edited text throughout.\\
\textbf{GT}: Contributed to Sec.~\ref{sec:intro} and~\ref{sec:problem_suitable}, and helped edit the paper.\\
\textbf{HX}: Contributed Sec.~\ref{subsec:accuracy}, to Sec.~\ref{sec:relative-fe-protocol}, and to Sec.~\ref{sec:are-they-good}.
% We suggest you preserve this comment:
For a more detailed description of author contributions,
see the GitHub issue tracking and changelog at \githubrepository.

\section*{Other Contributions}
%%%%%%%%%%%%%%%
% You should include all people who have filed issues that were
% accepted into the paper, or that upon discussion altered what was in the paper.
% Multiple significant contributions might mean that the contributor
% should be moved to authorship at the discretion of the a
%
% See the policies ``Policies on Authorship'' section of https://livecoms.github.io for
% more information on deciding on authorship and author order.
%%%%%%%%%%%%%%%
Julia E. Rice participated in the original discussion of the document at the Best Practices in Molecular Simulation Workshop Hosted by at NIST, Gaithersburg, MD, August 24th-25th, 2017.
Marieke Schor proofread the manuscript. 

% We suggest you preserve this comment:
For a more detailed description of contributions from the community and others, 
see the GitHub issue tracking and changelog at \githubrepository.


\section*{Potentially Conflicting Interests}
%%%%%%%
%Declare any potentially competing interests, financial or otherwise
%%%%%%%
JM is a current member of the Scientific Advisory Board of Cresset. 
MK is employed by Cresset who commercially distribute a software for performing alchemical free energy calculations. MRS is a Open Science Fellow and consultant for Silicon Therapeutics.
JDC is a current member of the Scientific Advisory Board of OpenEye Scientific Software and a consultant to Foresite Laboratories.
\section*{Funding Information}
%%%%%%%
% Authors should acknowledge funding sources here. Reference specific grants.
%%%%%%%
ASJSM and JM acknowledge funding through an EPSRC flagship software grant: EP/P022138/1
MK and JM acknowledge funding through Innovate UK by KTP partnership 011120.
BR - wrote 
AR acknowledges partial support from the Tri-Institutional Program in Computational Biology and Medicine and the Sloan Kettering Institute.
HEBM acknowledges support from a Molecular Sciences Software Institute Investment Fellowship and Relay Therapeutics.
DLM acknowledges support from the National Institutes of Health (R01GM108889, R01GM124270, and R01GM132386), and the National Science Foundation (CHE 1352608).
JDC acknowledges support from the National Institutes of Health (NIH P30 CA008748, NIH R01 GM121505, R01 GM132386).
A complete funding history for the Chodera lab can be found at \url{http://choderalab.org/funding}.
The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.

\section*{Author Information}
\makeorcid
\bibliography{alchemical,manual}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% APPENDICES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\appendix


\end{document}
